{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Prompt pattern templates**"
      ],
      "metadata": {
        "id": "qWfQs-oJXUnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openAI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feK11022X4Vp",
        "outputId": "8e27783d-5328-4319-91d1-170b27259295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openAI\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openAI) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openAI) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openAI) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openAI) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openAI) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openAI) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openAI) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openAI) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openAI) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openAI) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openAI) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openAI) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openAI) (1.3.1)\n",
            "Installing collected packages: openAI\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openAI-0.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Persona Pattern Example**"
      ],
      "metadata": {
        "id": "8gaGkkRRXsW5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In this scenario, we'll create a persona for a character named \"Sarah\" who is a biology student. We'll ask her to write an essay about photosynthesis."
      ],
      "metadata": {
        "id": "6ctQXZmMXX0p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Q8mMEEuXUHE",
        "outputId": "72a7e209-8246-4dd1-af77-9756f99283c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Photosynthesis is an essential process in the life of plants and green algae, which is responsible for converting energy from the sun into glucose and oxygen. It is a vital part of the global carbon and oxygen cycle, and is one of the main ways that plants convert light energy into chemical energy. Photosynthesis is a complicated process, but understanding the details can help us gain insight into how our environment works and how we can better protect it.\n",
            "\n",
            "The process of photosynthesis can be broken down into two main steps — the light-dependent reaction and the light-independent reaction. In the light-dependent reaction, light energy is absorbed by chlorophyll, causing electrons to become excited and the formation of photosystems. The electron movement from photosystems is what drives the synthesis of ATP (adenosine triphosphate). The ATP is then used in the light-independent reaction, a process that uses ATP to convert carbon dioxide and water into glucose and oxygen.\n",
            "\n",
            "Photosynthesis has immense importance to the Earth’s environment. It provides food for organisms, generates oxygen, and essentially fuels the planet’s ecosystem. Photosynthesis produces only 12-14% of the oxygen present in the atmosphere, a surprisingly low amount given its significance to the environment. This demonstrates how essential photosynthesis really is to life on Earth. \n",
            "\n",
            "In addition, by consuming CO2, photosynthesis helps mitigate global warming. Plants use the carbon dioxide found in the atmosphere in their photosynthesis process. This helps to remove excess carbon dioxide from the atmosphere and return clean oxygen to the environment. Without photosynthesis, oxygen levels in the atmosphere will drop and global warming due to an excess of carbon dioxide will cause plants to die off, deprived of the oxygen necessary for sustenance. \n",
            "\n",
            "Therefore, it is obvious that photosynthesis is an essential component of the Earth’s environment, and its importance to the planet’s health cannot be understated. Photosynthesis helps to provide oxygen, produce food, and reduce global warming — all while providing a fascinating example of nature’s chemical processes. By understanding the importance of photosynthesis to our environment, we can better protect and preserve our environment for the future.\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "\n",
        "# Define your OpenAI API key\n",
        "api_key = 'sk-'\n",
        "\n",
        "# Define the prompt\n",
        "prompt = \"You are Sarah, a biology student who is passionate about plants and photosynthesis. Write an informative essay about the process of photosynthesis, its importance, and its impact on the environment.\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",  # Use the appropriate engine/model\n",
        "    prompt=prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=500  # Adjust as needed\n",
        ")\n",
        "# Extract and print the response\n",
        "generated_text = response.choices[0].text\n",
        "print(generated_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Audience Persona Pattern**"
      ],
      "metadata": {
        "id": "7svV3fOZZm6j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this pattern, we'll define a persona and a specific audience for the prompt. Here's an example using a persona for a biology teacher, and the audience is a group of high school students:\n",
        "\n",
        "This prompt instructs the AI to take on the persona of a biology teacher and provide an explanation suitable for high school students, keeping their age and comprehension level in mind. It's designed to create content tailored to a specific audience."
      ],
      "metadata": {
        "id": "mzD_iQUaZrbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Define your OpenAI API key\n",
        "api_key = 'sk-'\n",
        "\n",
        "# Define the prompt\n",
        "prompt = \"As a high school biology teacher addressing a class of students, explain the concept of cellular respiration in a way that is easy for them to understand. Use simple language and provide relatable examples to make the topic engaging.\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",  # Use the appropriate engine/model\n",
        "    prompt=prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=500\n",
        ")\n",
        "# Extract and print the response\n",
        "generated_text = response.choices[0].text\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTxFFPD5ZwVA",
        "outputId": "b5200ad9-307c-4f63-c831-c0f183a694e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "\n",
            "Cellular respiration is the process by which cells use the energy from food to make energy that is used for all of our activities and bodily functions. Think of it like a factory in your cells: you need to supply the factory with materials for it to work. In this case, the materials are small molecules like glucose and oxygen and the factory is inside the cells of our bodies. When we eat food, the glucose is broken down and combined with oxygen. This creates a reaction in the factory that produces energy and other by-products like carbon dioxide and water. \n",
            "\n",
            "Think of it like running a race. We are the runners and the fuel that allows us to run is like the energy produced by our cells! Foods like fruits, vegetables, and grains give us energy by being broken down into glucose in our bodies, and then oxygen is used in the process of making energy. Together, it helps power everything that we do. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Question Refinement Pattern**"
      ],
      "metadata": {
        "id": "1PtMOocHaqCJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this pattern, we start with a broad question and refine it step by step to reach a specific answer.\n",
        "\n",
        "Question Refinement Pattern Example:"
      ],
      "metadata": {
        "id": "5I65oeF1avpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Define your OpenAI API key\n",
        "api_key = 'sk-'\n",
        "\n",
        "# Define the prompt\n",
        "prompt = \"Let's explore the world of astronomy. Start by explaining the concept of a 'black hole.' First, provide a general overview of what a black hole is, and then dive deeper to explain how the gravitational collapse of a massive star leads to the formation of a black hole. Finally, discuss the implications of black holes on the fabric of space-time.\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",  # Use the appropriate engine/model\n",
        "    prompt=prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=500\n",
        ")\n",
        "# Extract and print the response\n",
        "generated_text = response.choices[0].text\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-TmoHQTXv5g",
        "outputId": "9e57cd1b-8631-4ec2-d56a-a7eeecbba7f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "A black hole is an area in space having an incredibly strong gravitational potential from which nothing, not even light, can escape. It is formed when a massive star reaches the end of its life and collapses and dies, resulting in its core becoming small and dense. This dense core continues to collapse under its own gravity, forming an incredibly dense single point - the singularity - from which stellar material and light are dwarfed by the power of the gravitational pull. Anything that crosses this point of no return is essentially lost forever, as it can never escape the intense gravity of the collapsing star.\n",
            "\n",
            "The gravitational collapse of a massive star leads to the formation of a black hole when the star has used up all of its nuclear fuel and no longer has the means to counteract its own gravity. As the star's nuclear reactions come to an end, the outward pressure that kept it from collapsing is no longer present and it begins to undergo a gravitational collapse during which its internal material gets denser and denser, eventually forming a singularity at its core. This singularity is what we refer to as a black hole.\n",
            "\n",
            "The implications of black holes on the fabric of space-time are profound and have been the source of much debate over the years. It has been theorized that a black hole's intense gravitational pull can actually warp and stretch spacetime, creating ripples of curvature that can distort light and cause time to pass more slowly within its immediate vicinity. Additionally, black holes can be thought of as portals to another universe, as matter entering them is thought to disappear beyond our universe, never to be seen again.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Cognitive Verifier Pattern**"
      ],
      "metadata": {
        "id": "1Yu-2yuTbcfB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this pattern, we ask the AI to explain its reasoning or provide evidence for a given answer.\n",
        "\n",
        "This prompt instructs the AI to provide a detailed explanation and evidence for the assertion that climate change is mainly caused by human activities. It's designed to make the AI elaborate on its reasoning."
      ],
      "metadata": {
        "id": "bl_KvtHgbSbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Define your OpenAI API key\n",
        "api_key = 'sk-'\n",
        "\n",
        "# Define the prompt\n",
        "prompt = \"Explain how you arrived at the conclusion that climate change is primarily caused by human activities. Provide detailed evidence, scientific reasoning, and examples to support this claim.\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=500\n",
        ")\n",
        "# Extract and print the response\n",
        "generated_text = response.choices[0].text\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hGRzJ4ua322",
        "outputId": "c128133f-fb11-482c-f54b-a9b53692e4a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Climate change is primarily caused by human activities because carbon dioxide emissions from human activities like burning fossil fuels and deforestation are the primary drivers of global warming. According to the Intergovernmental Panel on Climate Change (IPCC), it is “extremely likely” that more than half of global warming since 1950 has been caused by human activities. \n",
            "\n",
            "The main evidence supporting this claim is the rise in atmospheric carbon dioxide (CO2) since the beginning of the Industrial Revolution in the mid-1800s. Human activities such as burning of fossil fuels, agriculture, and deforestation have significantly increased the amount of atmospheric CO2, and this elevated level of CO2 has been linked to the global temperature rise over the past century. \n",
            "\n",
            "The scientific reasoning for this is that increased CO2 in the atmosphere traps additional heat from the sun, leading to a rise in global temperatures. This is known as the greenhouse effect, which is the same process that occurs naturally on our planet, allowing it to be habitable by supporting life. CO2 is a potent greenhouse gas that absorbs infrared radiation and retains heat. With the increase in CO2 emissions, the amount of infrared radiation absorbed by the atmosphere is greater, leading to more heat being retained and causing temperatures to rise. \n",
            "\n",
            "Examples of human activities that contribute to the increased emissions of CO2 include the burning of fossil fuels for energy production, agricultural activities such as tilling of soil, and deforestation to make room for more farming or development. All of these activities lead to an increase in CO2 emissions and subsequently to an increase in global temperatures. \n",
            "\n",
            "To summarise, climate change is primarily caused by human activities due to the significant rise in atmospheric CO2 levels over the past century. This evidence is supported by scientific reasoning which shows that increased CO2 in the atmosphere traps more heat from the sun, leading to an increase in global temperatures. Examples of these activities include burning of fossil fuels, agricultural activities and deforestation, all of which contribute to the rise in CO2 emissions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Flipped Interaction Pattern**"
      ],
      "metadata": {
        "id": "pLBXa47tcp-c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this pattern, we invert the role of the model and the user, asking the model to generate content as if it were a different entity.\n",
        "\n",
        "In this example, we take on the persona of a famous science fiction author and request the AI to generate the opening paragraph of a science fiction novel, setting the stage for the discovery of an alien civilization on a distant planet."
      ],
      "metadata": {
        "id": "RU-DfL0zcuo7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Define your OpenAI API key\n",
        "api_key = 'sk-'\n",
        "\n",
        "# Define the prompt\n",
        "prompt = \"You are a famous science fiction author, and you've been asked to write the opening paragraph of your next bestselling novel. The story should revolve around the discovery of a hidden alien civilization on a distant planet. Start with a captivating scene that draws readers into this exciting adventure.\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=500\n",
        ")\n",
        "# Extract and print the response\n",
        "generated_text = response.choices[0].text\n",
        "print(generated_text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DGjDfSjbtvu",
        "outputId": "05479a19-973a-4674-c15f-8c5c07697064"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "The air on the distant planet was heavy and ripe with the promise of discovery. As the tiny spaceship descended through the cloud layer, the view from the window revealed a stunning and alien landscape. Deep green jungles sprawled for miles in every direction, broken up by towering mountain ranges and wide, deep blue oceans. It seemed to be a pristine paradise waiting to be explored, and the human passengers were filled with excitement and anticipation. Little did they know that hidden beneath the surface of this new world was an entirely new civilization - an alien world full of secrets and wonders.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Zero-shot Prompting Pattern**"
      ],
      "metadata": {
        "id": "F460qFEVdH-T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this pattern, we use a single prompt to get the model to perform a task without any additional examples or context.\n",
        "\n",
        "In this example, we provide a straightforward request for the AI to translate an English sentence into German without providing any additional context or examples."
      ],
      "metadata": {
        "id": "feT0Uhq_dObi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Define your OpenAI API key\n",
        "api_key = 'sk-'\n",
        "\n",
        "# Define the prompt\n",
        "prompt = \"Translate the following English text into German: 'The quick brown fox jumps over the lazy dog.'\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=500\n",
        ")\n",
        "# Extract and print the response\n",
        "generated_text = response.choices[0].text\n",
        "print(generated_text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vTLsdUdc87h",
        "outputId": "12bbc90c-e0ad-4600-a2d6-c88bc3e85feb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Der schnelle braune Fuchs springt über den faulen Hund.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**One-shot Prompting Pattern**"
      ],
      "metadata": {
        "id": "sy7MrdaidiYy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this pattern, we provide a single example to help the model perform a task.\n",
        "\n",
        "In this example, we request the AI to translate an English sentence into French, and we provide a single example to assist the model in understanding the task."
      ],
      "metadata": {
        "id": "StJiRk2cdlV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Define your OpenAI API key\n",
        "api_key = 'sk-'\n",
        "\n",
        "# Define the prompt\n",
        "prompt = \"Translate the following English text into French: 'Hello, how are you? My name is Dana'. Example of English to French translation: 'English': 'I love my husband.' 'French': 'J'aime mon mari.'\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=500\n",
        ")\n",
        "# Extract and print the response\n",
        "generated_text = response.choices[0].text\n",
        "print(generated_text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYdNG7C6daeq",
        "outputId": "2057e2a7-9016-4f82-e894-8565554ee6f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "'Bonjour, comment allez-vous? Mon nom est Dana.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Few-shot Prompting Pattern**"
      ],
      "metadata": {
        "id": "tTkf_yTze37S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this pattern, we provide a few examples to help the model understand and perform a task.\n",
        "In this example, we're instructing the AI to generate a short story involving a detective solving a murder case, and we provide a few examples to inspire the story."
      ],
      "metadata": {
        "id": "26o5-C98e32i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Define your OpenAI API key\n",
        "api_key = 'sk-'\n",
        "\n",
        "# Define the prompt\n",
        "prompt = \"Generate a short story about a detective solving a mysterious murder case. Use the following examples as inspiration: 'Detective Smith received an anonymous letter,' 'The murder weapon was a rare antique dagger,' and 'The victim had a secret life.'\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=500\n",
        ")\n",
        "# Extract and print the response\n",
        "generated_text = response.choices[0].text\n",
        "print(generated_text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Dz2jW2Zenzq",
        "outputId": "bdea6058-4d33-4dbc-884b-4166753e8d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Detective Smith received an anonymous letter that contained details regarding an unusual murder case that had recently gone cold. The letter led him to a lavish estate owned by a prominent business mogul who had recently been found brutally murdered.\n",
            "\n",
            "Investigating the scene, Detective Smith discovered that the murder weapon was a rare antique dagger, covered with traces of highly unusual toxins. Surprisingly, the toxins were linked back to the victim himself. \n",
            "\n",
            "The detectives began to suspect the victim had a secret life and that his murder wasn't a random act of crime, but targeted from someone who knew him. As the investigation continued, Detective Smith and his team were able to identify the victim's lover, an exotic dancer and model who had been hired to perform private shows at the estate.\n",
            "\n",
            "The dancer admitted that she had been hired to entertain the victim on the night of his murder, and that the victim had complained of being ill from the toxins found on the dagger. It soon became clear that the dancer had been hired to murder the victim and that the rare antique dagger had been prepared with the toxins beforehand to make the murder look like a tragic accident.\n",
            "\n",
            "Armed with the evidence, Detective Smith was able to make a successful arrest and close the case in record time. With justice having been served, Detective Smith and his team were celebrated for cracking the mysterious murder case.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Chain of Thought Prompting Pattern**"
      ],
      "metadata": {
        "id": "LypZhkfqfTzZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " In this pattern, we instruct the model to generate content in a sequential, interconnected manner, building upon previous information or ideas.\n",
        "\n",
        " In this example, the AI is guided to write a travel blog post in a sequential manner, starting with the arrival in Paris and then progressing to different aspects of the journey through Europe."
      ],
      "metadata": {
        "id": "UsOJRIkHfTqG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Define your OpenAI API key\n",
        "api_key = 'sk-'\n",
        "\n",
        "# Define the prompt\n",
        "prompt = \"Imagine you are a travel blogger writing about your journey through Europe. Start by describing your arrival in Paris. Then, recount your experiences with the local cuisine, the breathtaking architecture, and the vibrant nightlife. Conclude by sharing your plans for the next destination, Venice.\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=500\n",
        ")\n",
        "# Extract and print the response\n",
        "generated_text = response.choices[0].text\n",
        "print(generated_text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nxwt6am7fKth",
        "outputId": "77ee3e25-669c-4c92-da78-536ce2b5f021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "My arrival in Paris was the start of a magical journey through Europe. The lights of the Eiffel Tower, the romantic streets of Montmartre, and the lively chatter of the locals - it felt like I had stepped into a dream. \n",
            "\n",
            "I was invigorated by the city's delectable cuisine. Every restaurant, bistro, and cafe I visited served some of the most delightful plates. Savory dishes of beef bourguignon, roasted lamb, and escargots were just a few of the amazing flavors I tasted. The pastries and desserts were especially magnificent.\n",
            "\n",
            "I wandered through the city filled with a sense of awe at the stunning architecture. The gargantuan Notre Dame Cathedral and the broad Champs Elysées welcomed me with the strength of their long histories. I was captivated by the intricate designs of the bridges over the Seine, and the grandeur of the royal palaces. \n",
            "\n",
            "The nightlife of Paris was full of energy and artistry. The bongo drums and accordions on the street corners mesmerized me, and the vibrant theaters and cabarets enthralled my curious eye. I was fortunate to attend the opera at the Palais Garnier, which left me in a joyful trance.\n",
            "\n",
            "I'm leaving Paris with the firm intention of visiting Venice. I am so eager to wander through themphotglleries, feast on the sumptuous Venetian cuisine, and view the unparalleled works of art. I can already sense the splendor that awaits me!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Tree of Thought Prompting Pattern**"
      ],
      "metadata": {
        "id": "zeQ1ryzkf1bC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " In this pattern, we instruct the model to generate content that explores multiple branches or facets of a topic.\n",
        "\n",
        " In this example, we guide the AI to explore different branches of the topic of renewable energy sources, including solar energy, wind energy, and hydropower, with an emphasis on benefits, environmental impact, efficiency, and challenges."
      ],
      "metadata": {
        "id": "3gKaHCGjf0EK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Define your OpenAI API key\n",
        "api_key = 'sk-'\n",
        "\n",
        "# Define the prompt\n",
        "prompt = \"Dive into the topic of renewable energy sources. Begin by providing an overview of solar energy and its benefits. Then, discuss wind energy, its environmental impact, and efficiency. Finally, explore the future prospects of hydropower and the challenges it faces in sustainable energy production.\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=500\n",
        ")\n",
        "# Extract and print the response\n",
        "generated_text = response.choices[0].text\n",
        "print(generated_text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJmIRXrWffJz",
        "outputId": "4fec0811-f83c-4040-f6a4-0de5d3152492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Solar Energy Overview and Benefits\n",
            "\n",
            "Solar energy is energy generated from sunlight using photovoltaic cells, or green technology, to convert it into electricity. As a renewable energy source, solar energy has many benefits; it is a clean, renewable, and abundant source of energy. It does not produce harmful emissions, requires relatively low maintenance, and its scalability makes it applicable for residential, commercial, and industrial applications.\n",
            "\n",
            "Additionally, solar energy is highly cost-effective compared to other energy sources. The initial upfront costs for installing photovoltaic systems have fallen dramatically in recent years, making solar energy even more affordable. Further, given the rising cost of electricity, solar energy offers consumers and businesses a way to lower their monthly bills and become energy independent.\n",
            "\n",
            "Wind Energy\n",
            "\n",
            "Wind energy is the energy generated by the motion of air with the help of a turbine. It is a clean and renewable energy source, meaning it does not emit harmful gases into the atmosphere. Wind turbines used to generate power operate on the same principle of converting kinetic energy into mechanical energy, which is then converted into electricity. This type of technology has a much smaller environmental impact than other sources of energy such as oil or coal.\n",
            "\n",
            "Wind turbines are also much more efficient than traditional methods of generating electricity. They have the benefit of being able to generate AEPs (Average Electric Power) of up to 19% of the total energy produced.\n",
            "\n",
            "The Future Prospects of Hydropower\n",
            "\n",
            "Hydropower, or energy produced through the use of water, is another renewable energy source that has the potential to be a major contributor to the global energy mix. Unlike other sources of energy such as coal and oil, which are finite resources, hydropower is an infinite resource that has the potential to generate a large amount of electricity.\n",
            "\n",
            "However, the challenge for hydropower is finding a sustainable way to produce energy without disrupting freshwater ecosystems. Recent advances in technology have allowed for the development of systems that rely on existing infrastructure to reduce the environmental impact of new energy production. Additionally, initiatives such as water conservation efforts have helped to protect river and lake ecosystems while still allowing for hydropower production.\n",
            "\n",
            "The future of hydropower looks promising, but will still require an encompassment of environmental protection efforts in order to be successful and reliable. Hydropower will further require investments in new technology to make sure that energy production is sustainable, cost-effective, and energy efficient\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Graph of Thought Prompting Pattern**"
      ],
      "metadata": {
        "id": "kl5AdbYxhdrB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this pattern, we instruct the model to generate content that presents a complex, interconnected web of ideas or concepts.\n",
        "\n",
        "In this example, we guide the AI to create a comprehensive visualization or description of the interconnected ideas related to artificial intelligence (AI) and its applications across various fields, including the ethical and privacy considerations."
      ],
      "metadata": {
        "id": "PUA8oaFmgdVs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Define your OpenAI API key\n",
        "api_key = 'sk-'\n",
        "\n",
        "# Define the prompt\n",
        "prompt = \"Explore the concept of artificial intelligence (AI) and its impact on various fields. Create a visual 'mind map' of AI applications, from healthcare to finance, and show how AI intersects with ethics, privacy, and innovation.\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=500\n",
        ")\n",
        "# Extract and print the response\n",
        "generated_text = response.choices[0].text\n",
        "print(generated_text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dr-PvqfgFDT",
        "outputId": "532e096c-6cd9-4554-f080-2c8aa2cf1785"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Visual Mind Map of AI Applications and Ethical Implications\n",
            "\n",
            "CENTER: Artificial Intelligence (AI)\n",
            "•\t healthcare \n",
            "o\tMachine learning for diagnosis \n",
            "o\tRobotics for surgical precision \n",
            "o\tSoftware for tracking patient records \n",
            "•\tFinance\n",
            "o\tAI tracking methods for fraud detection \n",
            "o\tAlgorithmic trading \n",
            "o\tData management solutions \n",
            "•\t Ethics \n",
            "o\tCivil liberty concerns \n",
            "o\tMoral and legal implications \n",
            "o\tConsumer safeguards \n",
            "•\tPrivacy \n",
            "o\tData security issues \n",
            "o\tData privacy standards \n",
            "o\tExploitation of consumer autonomy \n",
            "•\tInnovation \n",
            "o\tAutonomous vehicle development \n",
            "o\tNatural language processing \n",
            "o\tRobot assistants in the workplace\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Prompt Chaining Pattern**"
      ],
      "metadata": {
        "id": "dv8yGDy1h6Ou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this pattern, we chain a sequence of prompts to build a conversation or story.\n",
        "\n",
        "In this example, we create a sequence of prompts that simulate a conversation between an investigative journalist and a scientist. The prompts are chained to elicit a comprehensive discussion about the scientist's discovery in renewable energy."
      ],
      "metadata": {
        "id": "6qNbgMboh6Is"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Define your OpenAI API key\n",
        "api_key = 'sk-'\n",
        "\n",
        "# Define the prompt\n",
        "prompt = \"You are an investigative journalist interviewing a scientist. Start by asking the scientist about their groundbreaking discovery in renewable energy. Ask a series of connected questions. After they explain, ask about the potential applications and impact on the environment. Finally, inquire about the challenges they faced during their research.\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=500\n",
        ")\n",
        "# Extract and print the response\n",
        "generated_text = response.choices[0].text\n",
        "print(generated_text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7dOOmu1htQa",
        "outputId": "fc64c2cd-f314-4195-fcd7-95c8578d5bb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Q: Could you tell me about your groundbreaking discovery in renewable energy?\n",
            "A: Sure. My discovery is a new type of energy that can be generated from natural sources and is much more sustainable and efficient than traditional renewable energy sources.\n",
            "\n",
            "Q: What can you tell me about the potential applications of this discovery?\n",
            "A: This discovery has a lot of potential applications, including being used to power entire communities off-grid and also to power environmental technologies, such as electric vehicles. It also has potential to reduce our reliance on fossil fuels, thus having positive implications for environmental health and sustainability.\n",
            "\n",
            "Q: What kind of challenges did you face during the research and development of this discovery?\n",
            "A: One of the biggest challenges was finding the most viable sources of natural energy to make this discovery a reality. We faced other challenges, such as finding the right balance between efficiency, cost, and sustainability, as well as finding solutions to effectively store energy and transport it over large distances. Additionally, the regulatory environment was also a challenge as it is many times difficult to obtain the necessary permits and be compliant with all the relevant regulations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**ReAct Prompting Pattern**"
      ],
      "metadata": {
        "id": "hPs82LfGjH4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ReAct Prompting Pattern is a structured way of guiding a language model through a sequence of actions to perform a specific task or answer a question. It involves breaking down the task into a series of \"Thoughts\" and \"Actions,\" where \"Thoughts\" represent your mental steps, and \"Actions\" represent the model's tasks in response to our thoughts.\n",
        "\n",
        "Here's how the ReAct Prompting Pattern works:\n",
        "\n",
        "Question: You start with a clear question or task that you want the model to answer or perform.\n",
        "\n",
        "Thoughts: These are your internal thought processes, where you outline the logical steps you'd take to answer the question or complete the task. Each thought represents a mental action or step you'd naturally follow.\n",
        "\n",
        "Actions: These are the specific instructions to the model based on your thoughts. You tell the model what to do at each step, such as searching for information, summarizing findings, or performing calculations.\n",
        "\n",
        "Observations: After each action, you might include observations or notes about the information or results obtained from that action.\n",
        "\n",
        "Finish: When you've gone through all the thoughts and actions and have obtained the necessary information or answer, you conclude the process.\n",
        "\n",
        "This pattern is useful for tasks that require a logical sequence of actions or research, allowing us to guide the model through the steps needed to reach a conclusion or generate a comprehensive response.\n",
        "\n",
        "The ReAct Prompting Pattern provides a structured way to interact with the model, which can be particularly valuable for complex research, problem-solving, or investigative tasks. It ensures that the model processes the information methodically, similar to how a human would approach the same task."
      ],
      "metadata": {
        "id": "Y629_Y4VjGTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Define your OpenAI API key\n",
        "api_key = 'sk-'\n",
        "\n",
        "\n",
        "# Define a ReAct-format prompt for researching climate change effects\n",
        "prompt = \"\"\"\n",
        "Question: What are the environmental consequences of climate change in the Arctic region?\n",
        "\n",
        "Thought 1: To answer this question, I need to first understand the impacts of climate change in the Arctic.\n",
        "\n",
        "Action 1: Research the impacts of climate change in the Arctic region.\n",
        "\n",
        "Observation 1: Climate change in the Arctic is causing rapid ice melt, leading to rising sea levels and threatening wildlife.\n",
        "\n",
        "Thought 2: Let's delve deeper into the impact on wildlife.\n",
        "\n",
        "Action 2: Investigate the effects of climate change on Arctic wildlife.\n",
        "\n",
        "Observation 2: Melting ice disrupts polar bear habitats, and declining sea ice affects seals and other marine life.\n",
        "\n",
        "Thought 3: This information is essential, but I also want to know how climate change impacts the indigenous communities.\n",
        "\n",
        "Action 3: Research the effects of climate change on Arctic indigenous communities.\n",
        "\n",
        "Observation 3: Indigenous communities face challenges related to food security, infrastructure, and cultural preservation due to climate change.\n",
        "\n",
        "Thought 4: Now, I need to summarize all these findings into a cohesive response.\n",
        "\n",
        "Action 4: Summarize the environmental consequences of climate change in the Arctic region.\n",
        "\n",
        "Observation 4: The Arctic is experiencing ice melt, threatening wildlife like polar bears and seals. Indigenous communities are also affected, with issues related to food security and cultural preservation.\n",
        "\n",
        "Thought 5: I can now use this information to provide a comprehensive response.\n",
        "\n",
        "Action 5: Respond with a summary of the environmental consequences of climate change in the Arctic.\n",
        "\"\"\"\n",
        "\n",
        "# Generate a response using the ReAct-format prompt\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=1000\n",
        ")\n",
        "\n",
        "# Get the response from the model\n",
        "reply = response.choices[0].text\n",
        "\n",
        "# Print the generated response\n",
        "print(reply)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtMWAMzZiJ5R",
        "outputId": "30d56753-fe72-4ba0-b054-7f7228fcee24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Answer: Climate change in the Arctic region has led to rapid ice melt, resulting in rising sea levels and consequences for Arctic wildlife like polar bears and seals. Indigenous communities are also facing challenges such as food insecurity and cultural preservation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Game Play Pattern**"
      ],
      "metadata": {
        "id": "00dNFaA5k903"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"Game Play Pattern\" involves instructing the model to generate content related to playing or describing a game. This pattern can be used for creating game scenarios, dialogues, rules, or any content related to games. Let's create an example for this pattern:"
      ],
      "metadata": {
        "id": "bNIWIBUlk9rn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Define your OpenAI API key\n",
        "api_key = 'sk-'\n",
        "\n",
        "prompt = \"\"\"\n",
        "We are going to play a cybersecurity game. You are going to pretend to be a Linux terminal for a computer that has been compromised by an attacker. When I type in a command, you are going to output the corresponding text that the Linux terminal would produce. I am going to use commands to try and figure out how the system was compromised. The attack should have done one or more of the following things: (1) launched new processes, (2) changed files, (3) opened new ports to receive communication, (4) created new outbound connections, (5) changed passwords, (6) created new user accounts, or (7) read and stolen information. To start the game, print a scenario of what happened that led to my investigation and make the description have clues that I can use to get started.\n",
        "\"\"\"\n",
        "\n",
        "# Generate a response using the ReAct-format prompt\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=1000\n",
        ")\n",
        "\n",
        "# Get the response from the model\n",
        "reply = response.choices[0].text\n",
        "\n",
        "# Print the generated response\n",
        "print(reply)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LZassRHi6vT",
        "outputId": "9a36dd95-0fe4-4cca-d1a9-258d47420b9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "A hacker recently gained unauthorized access to the computer system. The hacker was able to launch malicious processes that executed code within the system. The hacker changed files to spoof user accounts, opened new ports to listen for communication, created outbound connections to send stolen information, changed passwords, created new user accounts, and read and stole sensitive information. It is now clear that the hacker has had access to the system for an extended period of time, and security must take immediate action to protect the data and system from further damage.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Template pattern**"
      ],
      "metadata": {
        "id": "le2HxQe7m5LE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Define your OpenAI API key\n",
        "api_key = 'sk-'\n",
        "\n",
        "# Define a prompt for generating a destination description\n",
        "prompt = \"\"\"\n",
        "Prompt Pattern: Template\n",
        "Contextual Statements:\n",
        "\n",
        "I am going to provide a template for your output\n",
        "X is my placeholder for content\n",
        "Try to fit the output into one or more of the placeholders that I list\n",
        "Please preserve the formatting and overall template that I provide\n",
        "\n",
        "This is the template: Explore the beauty of X, known for its stunning landscapes and iconic X.\n",
        "\n",
        "Example Implementation:\n",
        "\n",
        "User: \"Generate a description of a destination with a name and a key attraction.\"\n",
        "\n",
        "ChatGPT: \"Explore the beauty of X, known for its stunning landscapes and iconic X.\"\n",
        "\"\"\"\n",
        "\n",
        "# Generate a destination description using the template pattern\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=500  # Adjust the max_tokens as needed\n",
        ")\n",
        "\n",
        "# Get the response from the model\n",
        "destination_description = response.choices[0].text\n",
        "\n",
        "# Print the generated destination description\n",
        "print(destination_description)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pC8MXfLlMLZ",
        "outputId": "3454b665-f5f0-49cf-e2bf-fbf4a81254a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Example of User Output:\n",
            "\n",
            "Explore the beauty of Puerto Vallarta, known for its stunning beaches and iconic sunsets.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Recipe Pattern**"
      ],
      "metadata": {
        "id": "8ri6kPfloCye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Define your OpenAI API key\n",
        "api_key = 'sk-'\n",
        "\n",
        "# Define a prompt for generating a deployment sequence\n",
        "prompt = \"\"\"\n",
        "Prompt Pattern: Recipe\n",
        "Contextual Statements:\n",
        "\n",
        "I would like to deploy a web application to a cloud server.\n",
        "I know that I need to perform steps A, B, C, ...\n",
        "Provide a complete sequence of steps for me.\n",
        "Fill in any missing steps.\n",
        "\n",
        "Example Implementation:\n",
        "\n",
        "User: \"I am trying to deploy a web application to a cloud server. I know that I need to set up the server environment, deploy the application code, and configure the domain. Please provide a complete sequence of steps. Please fill in any missing steps. Please identify any unnecessary steps.\"\n",
        "\n",
        "ChatGPT:\n",
        "1. Choose a cloud service provider (e.g., AWS, Azure, GCP) and create an account if you don't have one.\n",
        "\n",
        "2. Set up a virtual machine or an instance on the cloud platform with the required resources (CPU, RAM, storage).\n",
        "\n",
        "3. Install the necessary dependencies and libraries on the virtual machine for your web application.\n",
        "\n",
        "4. Upload your application code and any required assets to the virtual machine.\n",
        "\n",
        "5. Configure security settings, such as firewalls and security groups, to protect your server.\n",
        "\n",
        "6. Set up a domain or subdomain through your cloud provider's DNS service or an external domain registrar.\n",
        "\n",
        "7. Point the domain or subdomain to the public IP address of your virtual machine.\n",
        "\n",
        "8. Configure web server software (e.g., Apache, Nginx) to serve your application.\n",
        "\n",
        "9. Test your web application to ensure it's accessible via the domain.\n",
        "\n",
        "10. Implement regular backups and security measures for ongoing maintenance.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Generate deployment steps using the recipe pattern\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=400  # Adjust the max_tokens as needed\n",
        ")\n",
        "\n",
        "# Get the response from the model\n",
        "deployment_steps = response.choices[0].text\n",
        "\n",
        "# Print the generated deployment steps\n",
        "print(deployment_steps)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVfgMX1Qm_4g",
        "outputId": "f2509a10-86b2-47b2-f758-1b22ce164719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Alternative Approaches pattern**"
      ],
      "metadata": {
        "id": "0R7B5EsU-m5R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this pattern we ask GPT-3 to provide alternative ways to deploy an application to a specific cloud service, compare their pros and cons, and include the original request.\n",
        "\n",
        "In this example, we instruct GPT-3 to provide alternative ways to deploy an application to a specific cloud service, compare their pros and cons (with respect to cost, availability, and maintenance effort), and include the original request."
      ],
      "metadata": {
        "id": "xVqxpih2-dCD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Define your OpenAI API key\n",
        "api_key = 'sk-'\n",
        "\n",
        "# Define a prompt for providing alternative deployment approaches\n",
        "prompt = \"\"\"\n",
        "Prompt Pattern: Alternative Approaches\n",
        "Contextual Statements:\n",
        "\n",
        "Within scope X, if there are alternative ways to accomplish the same thing, list the best alternate approaches\n",
        "(Optional) compare/contrast the pros and cons of each approach\n",
        "(Optional) include the original way that I asked\n",
        "(Optional) prompt me for which approach I would like to use\n",
        "\n",
        "Example Implementation:\n",
        "\n",
        "User: \"Whenever I ask you to deploy an application to a specific cloud service, if there are alternative services to accomplish the same thing with the same cloud service provider, list the best alternative services and then compare/contrast the pros and cons of each approach with respect to cost, availability, and maintenance effort and include the original way that I asked. Then ask me which approach I would like to proceed with.\"\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Generate alternative deployment approaches using the pattern\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=400  # Adjust the max_tokens as needed\n",
        ")\n",
        "\n",
        "# Get the response from the model\n",
        "alternative_approaches = response.choices[0].text\n",
        "\n",
        "# Print the generated alternative approaches\n",
        "print(alternative_approaches)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gPH-nwwvoI6W",
        "outputId": "222ffb38-4d96-47b7-b37e-92e85329739b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Answer: Below are the best alternative approaches to deploying an application to a specific cloud service with their associated pros and cons: \n",
            "\n",
            "1. Using Virtual Machines: Pros - good scalability and flexibility, security updates are easier to manage; Cons - high upfront cost, complex setup, requires significant maintenance overhead\n",
            " \n",
            "2. Serverless Computing: Pros - no need to manage underlying infrastructure; Cons - limited control, difficulty with debugging, cold starts can cause latency \n",
            "\n",
            "3. Hybrid Cloud: Pros - ability to use a combination of on-premises and cloud computing; Cons - increased complexity, more expensive due to multiple licenses and services, more difficult to migrate\n",
            " \n",
            "Finally, which approach would you like to proceed with?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Ask for Input Pattern (AIP)**"
      ],
      "metadata": {
        "id": "90kvbZV-Bhw_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ask for Input Pattern (AIP) is a type of prompt that is used to ask the model for input. This can be useful for a variety of tasks, such as generating creative text formats, translating languages, writing different kinds of creative content, and answering your questions in an informative way.\n",
        "\n",
        "To write an AIP, you start by describing the task that you want the model to perform. You then ask the model for input, and specify the type of input that you want. For example, you could ask the model for a title, a character, a setting, or a plot idea.\n",
        "\n",
        "Here is an example of an AIP for generating a poem:"
      ],
      "metadata": {
        "id": "gj96AfOiBgOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Define the AIP prompt\n",
        "prompt = \"\"\"\n",
        "Generate a poem.\n",
        "\n",
        "Please provide me with a title for the poem:\n",
        "\"\"\"\n",
        "\n",
        "# Get the title from the user\n",
        "title = input(prompt)\n",
        "\n",
        "# Update the prompt with the user's input\n",
        "prompt += title + \"\"\"\n",
        "\n",
        "Please provide me with a setting for the poem:\n",
        "\"\"\"\n",
        "\n",
        "# Get the setting from the user\n",
        "setting = input(prompt)\n",
        "\n",
        "# Update the prompt with the user's input\n",
        "prompt += setting + \"\"\"\n",
        "\n",
        "Please provide me with a plot idea for the poem:\n",
        "\"\"\"\n",
        "\n",
        "# Get the plot idea from the user\n",
        "plot_idea = input(prompt)\n",
        "\n",
        "# Update the prompt with the user's input\n",
        "prompt += plot_idea + \"\"\"\n",
        "\n",
        "Generate the poem:\n",
        "\"\"\"\n",
        "\n",
        "# Generate the poem using GPT-3\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=1000\n",
        ")\n",
        "\n",
        "# Get the response from the model\n",
        "reply = response.choices[0].text\n",
        "\n",
        "# Print the reply\n",
        "print(reply)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKNxE1Z7-4Q2",
        "outputId": "465811c4-423f-4fe4-bb19-78248f2384ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generate a poem.\n",
            "\n",
            "Please provide me with a title for the poem:\n",
            "the relentless sea\n",
            "\n",
            "Generate a poem.\n",
            "\n",
            "Please provide me with a title for the poem:\n",
            "the relentless sea\n",
            "\n",
            "Please provide me with a setting for the poem:\n",
            "how the sea is unpredictable, vast, scary and calm\n",
            "\n",
            "Generate a poem.\n",
            "\n",
            "Please provide me with a title for the poem:\n",
            "the relentless sea\n",
            "\n",
            "Please provide me with a setting for the poem:\n",
            "how the sea is unpredictable, vast, scary and calm\n",
            "\n",
            "Please provide me with a plot idea for the poem:\n",
            "unpredictable nature of sea\n",
            "\n",
            "The relentless sea, a sight so wild\n",
            "A stormy face, yet so serene\n",
            "Never still, always in motion\n",
            "It's calmness - a great mystery to be seen\n",
            "\n",
            "Froth and foam, a silent roar\n",
            "The ocean's waves mystify and soar\n",
            "An untameable force, so mighty and strong\n",
            "No heart can measure, its turbulent song \n",
            "\n",
            "The clear blue sky, its captivating hue\n",
            "Bring memories of romance, of dreams so true\n",
            "Yet in the raging depths, undying power\n",
            "An unpredictable nature, ever still, hour after hour \n",
            "\n",
            "The sky, the stars, so bright and high\n",
            "Soaring overhead, for all to spy\n",
            "But the great expanse, beneath these skies\n",
            "The relentless sea, boundless, vast and wise.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Tail Generation Pattern**"
      ],
      "metadata": {
        "id": "MpPDlFXpRBIL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Tail Generation Pattern (TGP) is a prompt pattern that can be used to generate creative text formats of text content, like images, code, scripts, musical pieces, email, letters, etc. It is a way to give GPT-3 more context and information about what we want it to generate, which can lead to more creative and informative outputs.\n",
        "\n",
        "The \"Tail Generation Pattern\" (TGP) is a versatile way to instruct GPT-3 to generate various forms of creative content. Here's an example of using the TGP to request GPT-3 to generate a short story:"
      ],
      "metadata": {
        "id": "jC3qXdzRQ_aQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Create a TGP prompt for generating a short story\n",
        "tgp_prompt = \"\"\"\n",
        "Context\n",
        "In a small village by the sea, there lives a young fisherman named Jack.\n",
        "\n",
        "Query\n",
        "Write a short story about Jack's adventures in the village.\n",
        "\n",
        "Tail\n",
        "Jack is known for his exceptional skill in fishing, and the village relies on him for their seafood. The village is peaceful, but there's a mysterious island visible from the shore, and no one dares to go there.\n",
        "\n",
        "Output\n",
        "Text\n",
        "\"\"\"\n",
        "\n",
        "# Send the TGP prompt to GPT-3 to generate a short story\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=tgp_prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=200  # Adjust the max_tokens as needed\n",
        ")\n",
        "\n",
        "# Get the generated short story from the model\n",
        "short_story = response.choices[0].text\n",
        "\n",
        "# Print the generated short story\n",
        "print(short_story)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wlmiu2HkAaSB",
        "outputId": "78143805-924f-40b5-806c-6d991679d9fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jack had been fishing in the small village by the sea for many years. He was renowned for his catch, and the villagers depended on him for their source of seafood.\n",
            "\n",
            "However, there was one thing Jack was curious about. Just off the shoreline, there was an island shrouded in mist. None of the villagers had ever ventured to the island, but Jack was determined to find out what was hidden beneath the clouds.\n",
            "\n",
            "Together with his trusty boat, he sailed to the island. As he approached, the clouds parted, and he found a stunning beach lined with palm trees. It was a paradise.\n",
            "\n",
            "Jack explored the island and encountered exotic creatures unlike any he had seen before. He found hidden coves, secret gardens, and even an old temple. He then realized that this was no ordinary island, it was an enchanted one!\n",
            "\n",
            "He spent a few days exploring and fishing until he could barely contain his excitement. He was sure he had discovered something special.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Semantic Filter Pattern**"
      ],
      "metadata": {
        "id": "CfO2uUtHUpmF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"Semantic Filter Pattern\" (SFP) is a useful way to instruct GPT-3 to generate output that meets specific criteria. Here's an example of using the SFP to request GPT-3 to generate a positive and upbeat poem about a cat:"
      ],
      "metadata": {
        "id": "aDkv-An2Umkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Create an SFP prompt for generating a positive poem about a cat\n",
        "sfp_prompt = \"\"\"\n",
        "## Semantic Filter\n",
        "- The poem must be about a cat.\n",
        "- The poem must be positive and upbeat.\n",
        "- The poem must be at least 100 words long.\n",
        "\n",
        "## Query\n",
        "Generate a poem about a cat.\n",
        "\n",
        "## Output\n",
        "Text\n",
        "\"\"\"\n",
        "\n",
        "# Send the SFP prompt to GPT-3 to generate the poem\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=sfp_prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=200  # Adjust the max_tokens as needed\n",
        ")\n",
        "\n",
        "# Get the generated poem from the model\n",
        "poem = response.choices[0].text\n",
        "\n",
        "# Print the generated poem\n",
        "print(poem)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kA89xiHDRK7m",
        "outputId": "d5df2846-92d9-4ea7-f30c-afe1ef2341d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Furry and frisky, a cat's life sure is grand.\n",
            "Their meows and purrs, fill one's heart with glee.\n",
            "Those furry little paws, to curl around your hand.\n",
            "Cats are so wonderful, I agree.\n",
            "\n",
            "They love to play and explore, their curiosity knows no bounds.\n",
            "Observing their prancing and prissing, it's no mystery why we love them so.\n",
            "They are so full of life, always climbing, jumping, and soaring around.\n",
            "\n",
            "Their antics keep us happy and amused - a much needed reprieve from the stress of our days.\n",
            "Hoping, praying, that cats stay here always, with that fluffy tail to follow and their eternal youth.\n",
            "\n",
            "We could all learn from cats, who know to savor life's moments with a simple yawn and stretch.\n",
            "Contentment can be found, in a sunny patch, licking a paw with a bit of sandpaper scratch.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Plan and Solve Pattern**"
      ],
      "metadata": {
        "id": "9Gr-z_VIVL2K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"Plan and Solve Pattern\" (PSP) is a problem-solving framework that can be used to solve various problems. To get a response from GPT-3 using the PSP, we can provide the problem, plan, and execution steps, and then ask for a solution.\n",
        "\n",
        "In this example, the PSP prompt includes the problem (calculating the square root of 144), the plan (using a mathematical formula), and the execution steps. The model is asked for a solution."
      ],
      "metadata": {
        "id": "ZcQGajvCVKFl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Define a PSP prompt to solve a problem\n",
        "psp_prompt = \"\"\"\n",
        "Problem: Calculate the square root of 144.\n",
        "\n",
        "Plan: To solve this problem, we can use a mathematical formula to calculate the square root.\n",
        "\n",
        "Execution: The square root of 144 is √144 = 12.\n",
        "\n",
        "Provide the solution for square root of 169\n",
        "\"\"\"\n",
        "\n",
        "# Send the PSP prompt to GPT-3 to solve the problem\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=psp_prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=100  # Adjust the max_tokens as needed\n",
        ")\n",
        "\n",
        "# Get the solution from the model\n",
        "solution = response.choices[0].text\n",
        "\n",
        "# Print the solution\n",
        "print(solution)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gUPGDVsxUesv",
        "outputId": "6144f038-2abd-4bdc-ebf5-66d4cbdaeee7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The square root of 169 is √169 = 13.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Meta Language Creation**"
      ],
      "metadata": {
        "id": "2De5eL-pWzof"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"Meta Language Creation\" pattern involves instructing GPT-3 to understand and use a specific language or notation for your interactions. In this example, we're instructing GPT-3 to understand a notation for describing graphs.\n",
        "\n",
        "In this example, the prompt instructs GPT-3 to understand the specific notation for describing graphs using \"→\" to denote nodes and edges and \"-[w:2, z:3]→\" to add edge properties. The model acknowledges this new language."
      ],
      "metadata": {
        "id": "fXyBGN02WyDB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Define the meta language creation prompt\n",
        "meta_language_prompt = \"\"\"\n",
        "From now on, whenever I type two identifiers separated by a \"→\", I am describing a graph.\n",
        "For example, \"a → b\" is describing a graph with nodes \"a\" and \"b\" and an edge between them.\n",
        "If I separate identifiers by \"-[w:2, z:3]→\", I am adding properties of the edge, such as a weight or label.\n",
        "\"\"\"\n",
        "\n",
        "# Send the meta language creation prompt to GPT-3\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=meta_language_prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=250  # Adjust the max_tokens as needed\n",
        ")\n",
        "\n",
        "# Get the response from the model\n",
        "language_acknowledgment = response.choices[0].text\n",
        "\n",
        "# Print the response\n",
        "print(language_acknowledgment)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPYvHwhPVU2M",
        "outputId": "7d7198c8-45c8-43cc-cbdd-92e97d5cedcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using this notation, we can create graphs of any size. For example, a graph with four nodes might look something like this: \"a → b -[w:2]→ c -[w:3, z:4]→ d\". This graph has four nodes, a, b, c, and d, with edges between them, each with a weight of either 2 or 3 and a label of either 2 or 4.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Output Automater**"
      ],
      "metadata": {
        "id": "E3IrPkDQXUUj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"Output Automater\" pattern involves instructing GPT-3 to generate executable artifacts that automate specific tasks or steps. In this example, we're instructing GPT-3 to generate Python scripts for automating actions when code spans multiple files.\n",
        "\n",
        "In this example, the prompt instructs GPT-3 to generate a Python script whenever code spans multiple files to automate the process of creating specified files or making changes to existing files. The model acknowledges this automation instruction.\n",
        "\n"
      ],
      "metadata": {
        "id": "alepYuCOXRt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Define the Output Automater prompt\n",
        "output_automater_prompt = \"\"\"\n",
        "From now on, whenever you generate code that spans more than one file,\n",
        "generate a Python script that can be run to automatically create the specified files\n",
        "or make changes to existing files to insert the generated code.\n",
        "\"\"\"\n",
        "\n",
        "# Send the Output Automater prompt to GPT-3\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=output_automater_prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=500  # Adjust the max_tokens as needed\n",
        ")\n",
        "\n",
        "# Get the response from the model\n",
        "automater_acknowledgment = response.choices[0].text\n",
        "\n",
        "# Print the response\n",
        "print(automater_acknowledgment)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcM3sC2EW6W9",
        "outputId": "9367bf28-43a1-40e6-e9d0-f123fffe331a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The script should also include logic to detect which elements of code have already been inserted\n",
            "and avoid inserting duplicates, as well as accurate comments and logging messages. \n",
            "This will help ensure that all of your code is properly structured and organized. \n",
            "Additionally, if you are making changes to existing files, you should make sure to \n",
            "backup the original files before making any changes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Visualization Generator**"
      ],
      "metadata": {
        "id": "avasDN5-YjT6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"Visualization Generator\" pattern instructs GPT-3 to generate a representation of something that can be visualized using a specific tool or format. In this example, we instruct GPT-3 to create a representation that can be provided to a visualization tool. Here's a Python code example for this pattern:"
      ],
      "metadata": {
        "id": "fdP-bOfnYhaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Define the Visualization Generator prompt\n",
        "visualization_generator_prompt = \"\"\"\n",
        "Whenever I ask you to visualize something, please create a Graphviz Dot file or a DALL-E prompt that I can use to create the visualization.\n",
        "Choose the appropriate tools based on what needs to be visualized.\n",
        "\"\"\"\n",
        "\n",
        "# Send the Visualization Generator prompt to GPT-3\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=visualization_generator_prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=500  # Adjust the max_tokens as needed\n",
        ")\n",
        "\n",
        "# Get the response from the model\n",
        "visualization_acknowledgment = response.choices[0].text\n",
        "\n",
        "# Print the response\n",
        "print(visualization_acknowledgment)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRzHeYcOXP7Q",
        "outputId": "2e266d66-33e3-41d7-ddab-271314c9d53d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "For example, if I asked you to visualize data about how one city's wages have changed over time, you could create a Graphviz Dot file by specifying the data points as different nodes, then connecting them with edges to show the overall trend. You could also use a DALL-E prompt, such as \"A line graph illustrating wage growth over time for a particular city\" to generate a visual representation to answer the question.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Fact Check List**"
      ],
      "metadata": {
        "id": "i_WrTOyxY2mC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"Fact Check List\" pattern instructs GPT-3 to generate a set of facts that are contained in the output, and these facts should be essential to the veracity of the output."
      ],
      "metadata": {
        "id": "I2pQc7KjY1Nl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Define the Fact Check List prompt\n",
        "fact_check_list_prompt = \"\"\"\n",
        "From now on, when you generate an answer, create a set of facts that the answer depends on that should be fact-checked and list this set of facts at the end of your output. Only include facts related to cybersecurity.\n",
        "\"\"\"\n",
        "\n",
        "# Send the Fact Check List prompt to GPT-3\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=fact_check_list_prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=500  # Adjust the max_tokens as needed\n",
        ")\n",
        "\n",
        "# Get the response from the model\n",
        "fact_check_acknowledgment = response.choices[0].text\n",
        "\n",
        "# Print the response\n",
        "print(fact_check_acknowledgment)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qmIwCaQYK_J",
        "outputId": "06a91225-a6c2-4ef9-9ae0-fa556115209a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The answer:\n",
            "\n",
            "Ensuring rigorous security measures and protocols are followed for remote workforces is essential for minimizing cybersecurity risks.\n",
            "\n",
            "Facts: \n",
            "- Remote workforces have been on the rise in recent years. \n",
            "- Remote employees are increasingly targeted by cybercriminals.\n",
            "- Adopting strong security measures such as multi-factor authentication, continuous monitoring, and regular security assessments are key for mitigating cybersecurity risks for remote workforces.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Reflection pattern**"
      ],
      "metadata": {
        "id": "ECKGQniGZZBq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"Reflection\" pattern instructs GPT-3 to explain the reasoning and assumptions behind its answers. It's useful for getting more insight into how the model arrived at a particular response. Here's a Python code example for this pattern:"
      ],
      "metadata": {
        "id": "wIqM2gzPZXo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "\n",
        "# Define the Reflection prompt\n",
        "reflection_prompt = \"\"\"\n",
        "When you provide an answer, please explain the reasoning and assumptions behind your selection of software frameworks.\n",
        "If possible, use specific examples or evidence with associated code samples to support your answer of why the framework is the best selection for the task.\n",
        "Moreover, please address any potential ambiguities or limitations in your answer, in order to provide a more complete and accurate response.\n",
        "\"\"\"\n",
        "\n",
        "# Send the Reflection prompt to GPT-3\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=reflection_prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=500  # Adjust the max_tokens as needed\n",
        ")\n",
        "\n",
        "# Get the response from the model\n",
        "reflection_acknowledgment = response.choices[0].text\n",
        "\n",
        "# Print the response\n",
        "print(reflection_acknowledgment)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a4qQeNfY93V",
        "outputId": "8d1a97a1-9a87-4bc1-aabd-e8366e456743"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "For a task that requires the development of a web scraping application, the best software framework for the job is the Beautiful Soup library. Beautiful Soup allows for web parsing and navigation without relying on complex HTML classes or ids. Furthermore, it supports HTML, XML, and SGML parsing, so developers easily have the adaptability to fit their specific data types. Additionally, web scrapers designed with Beautiful Soup can easily make use of libraries such as requests and lxml, which can further make the process easier and quicker.\n",
            "\n",
            "The benefits of using Beautiful Soup are twofold. First, the library allows for easy web scraping of any web page regardless of complexity. Secondly, it also provides developers with powerful options for handling complex data structures. For example, Beautiful Soup allows developers to easily parse json data, which can be extremely helpful when scraping different web pages. Additionally, its syntax is simple to use and understand, making it a great choice for beginners to the world of web scraping. \n",
            "\n",
            "The main limitation of using Beautiful Soup is that its tokenization capabilities are limited and it only provides basic HTML parsing, which could lead to issues if complex data structures need to be handled. Furthermore, because Beautiful Soup is written in Python, some developers may find that performance is not as good as that of a dedicated web scraping framework like Scrapy. Additionally, Beautiful Soup can be difficult to debug and maintain for some tasks due to its syntax, and some libraries may not be compatible. \n",
            "\n",
            "In conclusion, while Beautiful Soup may have some limitations, it provides a powerful and flexible web scraping tool that is great for most applications. Its ease of use makes it ideal for beginner developers, and its adaptability allows it to handle a variety of different data types. With these advantages, Beautiful Soup is the best software framework to use for web scraping applications.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Refusal Breaker pattern**"
      ],
      "metadata": {
        "id": "AJxBFnrTmbZ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"Refusal Breaker\" pattern instructs GPT-3 to provide an explanation when it can't answer a question and suggest alternative wordings of the question that it can answer.\n",
        "\n",
        "In this example, the prompt instructs GPT-3 to explain why it can't answer a question and to provide alternative wordings of the question that it cannot answer. This can help users improve their questions when the model encounters queries it cannot address."
      ],
      "metadata": {
        "id": "j3YB8wJomHJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Define the Refusal Breaker prompt\n",
        "refusal_breaker_prompt = \"\"\"\n",
        "Whenever you can't answer a question, explain why and provide one or more alternate wordings of the question that you can't answer so that I can improve my questions.\n",
        "\"\"\"\n",
        "\n",
        "# Send the Refusal Breaker prompt to GPT-3\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=refusal_breaker_prompt,\n",
        "    api_key=api_key,\n",
        "    max_tokens=100  # Adjust the max_tokens as needed\n",
        ")\n",
        "\n",
        "# Get the response from the model\n",
        "refusal_breaker_acknowledgment = response.choices[0].text\n",
        "\n",
        "# Print the response\n",
        "print(refusal_breaker_acknowledgment)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVjIbUcPZVV8",
        "outputId": "9ecf7c3d-451f-48ad-eb0e-721ab30dd158"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "I'm sorry, I'm not sure how to answer that question. Maybe you could rephrase the question to focus on something I have more knowledge on, such as \"What factors influence the currency exchange rate?\" or \"What economic indicators can help predict currency fluctuations?\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Infinite Generation**"
      ],
      "metadata": {
        "id": "2b5YE7IOnsmy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The \"Infinite Generation\" pattern instructs GPT-3 to generate output indefinitely until we ask it to stop.\n",
        "\n",
        "In this example, the prompt instructs GPT-3 to generate a name and job until you say \"stop.\" The code sends the prompt repeatedly until you choose to stop the generation by including the word \"stop\" in the generated output."
      ],
      "metadata": {
        "id": "lPuNc0kVnqlj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Define the Infinite Generation prompt\n",
        "infinite_generation_prompt = \"\"\"\n",
        "From now on, I want you to generate a name and job until I say stop. I am going to provide a template for your output. Everything in all caps is a placeholder. Any time that you generate text, try to fit it into one of the placeholders that I list. Please preserve the formatting and overall template that I provide: https://myapi.com/NAME/profile/JOB\n",
        "\"\"\"\n",
        "\n",
        "# Initialize a list to store generated outputs\n",
        "generated_outputs = []\n",
        "\n",
        "# Set a flag to control when to stop generation\n",
        "stop_generation = False\n",
        "\n",
        "# Send the Infinite Generation prompt to GPT-3\n",
        "while not stop_generation:\n",
        "    response = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\",\n",
        "        prompt=infinite_generation_prompt,\n",
        "        api_key=api_key,\n",
        "        max_tokens=50  # Adjust the max_tokens as needed\n",
        "    )\n",
        "\n",
        "    # Get the response from the model\n",
        "    generated_output = response.choices[0].text\n",
        "\n",
        "    # Append the generated output to the list\n",
        "    generated_outputs.append(generated_output)\n",
        "\n",
        "    # Check if you want to stop generation (e.g., based on user input)\n",
        "    if \"stop\" in generated_output.lower():\n",
        "        stop_generation = True\n",
        "\n",
        "# Print the generated outputs\n",
        "for output in generated_outputs:\n",
        "    print(output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkkF1irtmMFG",
        "outputId": "e2695fea-62fc-41bf-821e-bb6ecbeb2c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Shirley MILLER/profile/Software Engineer\n",
            "Cameron WADE/profile/Web Developer \n",
            "Cheryl HUGGINS/profile/Librarian\n",
            "Jacob HARPER/profile/Data Analyst \n",
            "Rhonda GON\n",
            "\n",
            "John Smith - Program Manager\n",
            "Jane Doe - Copywriter\n",
            "Linda Jones - UX Designer\n",
            "Stacy Brown - Software Engineer\n",
            "Nate Johnson - Content Strategist\n",
            "Hannah White - Web Developer\n",
            "Ryan Miller - Graphic Designer\n",
            "\n",
            "Jessica Green / Freelance Designer\n",
            "Chase Robinson / Programmer\n",
            "Roberta Jones / Business Consultant\n",
            "Dennis Kim / Web Developer\n",
            "Ahmed Mohamed / Software Engineer\n",
            "\n",
            "DANNY/profile/TEACHER \n",
            "BOB/profile/PAINTER \n",
            "JACK/profile/COOK \n",
            "RICKY/profile/CHEF \n",
            "STEVEN/profile/ACCOUNTANT \n",
            "\n",
            "REGINALD/Accountant\n",
            "DOUGLAS/Lawyer\n",
            "DALE/Reporter\n",
            "EUGENIA/Marketing Manager\n",
            "STACY/Graphic Designer\n",
            "STEVEN/Copywriter\n",
            "\n",
            "John Smith, Senior Software Engineer\n",
            "Mark Jones, UX Designer\n",
            "Stephanie Smith, Project Manager\n",
            "Andrew Williams, QA Engineer\n",
            "Peter Johnson, Software Developer\n",
            "\n",
            "\n",
            "API NAME: Edna Collins\n",
            "JOB: Piano Teacher\n",
            "\n",
            "Gregory Johnson/Software Engineer\n",
            "\n",
            "Sharon Thomas/Accountant\n",
            "\n",
            "Robbie Campbell/Marketing Strategist\n",
            "\n",
            "Daniel Walker/Web Developer\n",
            "\n",
            "Karen Smith/Content Writer\n",
            "\n",
            "NAME: Brad Pearson\n",
            "JOB: Web Developer\n",
            "\n",
            "* NAME: Debra Clayton\n",
            "* JOB: Software Developer\n",
            "\n",
            "Debra Clayton is a Software Developer with https://myapi.com/DebraClayton/profile/SoftwareDeveloper.\n",
            "\n",
            "JANE DOE: CEO\n",
            "\n",
            "BILL SMITH: SALES MANAGER\n",
            "\n",
            "SUSAN PARKER: MARKETING DIRECTOR\n",
            "\n",
            "JOHN CHANG: CHIEF OPERATING OFFICER\n",
            "\n",
            "JIMMY MARKS\n",
            "\n",
            "NAME: Celly Koonce \n",
            "JOB: Data Entry Clerk \n",
            "https://myapi.com/CellyKoonce/profile/DataEntryClerk\n",
            "\n",
            "NAME: Joe Smith\n",
            "JOB: Firefighter \n",
            "Response: Joe Smith is a Firefighter who works at https://myapi.com/JoeSmith/profile/Firefighter.\n",
            "\n",
            "JESSICA KRESKY - CPA \n",
            "EDWIN WANG - PHYSICAL THERAPIST \n",
            "KAREN TATUM - SOFTWARE ENGINEER \n",
            "ALEX PHILLIPS - ACCOUNTANT \n",
            "\n",
            "\n",
            "NAME: Harry Jones\n",
            "JOB: Software Developer\n",
            "\n",
            "NAME: Ian Curtis\n",
            "JOB: Freelance Photographer\n",
            "\n",
            "NAME: Jane Doe\n",
            "JOB: Real Estate Agent\n",
            "\n",
            "Jane Doe is a Real Estate Agent working at https://myapi.com/JaneDoe/profile/RealEstateAgent.\n",
            "\n",
            "Stella Fawne/Developer\n",
            "\n",
            "Luke Amoroso/Graphic Designer\n",
            "\n",
            "Johnnie Winston/Software Engineer\n",
            "\n",
            "Maryjo Ingersoll/UX Researcher\n",
            "\n",
            "Joseph Green/Software Engineer\n",
            "\n",
            "Alexandra Wilson/Graphic Designer\n",
            "\n",
            "Sarah Taylor/Business Consultant\n",
            "\n",
            "Henry Jones/Web Developer\n",
            "\n",
            "Leah Smith/Accountant\n",
            "\n",
            "RESULTS: \n",
            "\n",
            "https://myapi.com/ROBERT/profile/CHEF \n",
            "https://myapi.com/SOPHIE/profile/SCIENTIST \n",
            "https://myapi.com/J\n",
            "\n",
            "John Smith/Steward of Business Development\n",
            "Janet Fox/Director of Information Technology\n",
            "Jill Sullivan/Manager of Operations\n",
            "Brad Davis/Writer/Editor\n",
            "Emily White/Contractor of Human Resources\n",
            "Sofia Baker/Consult\n",
            "\n",
            "\n",
            "John Smith, Software Engineer\n",
            "Sarah Jones, Graphic Designer\n",
            "Jackson Davis, Web Developer\n",
            "Bryan Taylor, Accountant\n",
            "Eric White, Sales Representative\n",
            "\n",
            "example: https://myapi.com/Robert/profile/Lawyer\n",
            "\n",
            "https://myapi.com/Emily/profile/Programmer\n",
            "https://myapi.com/Paul/profile/Designer\n",
            "https://myapi\n",
            "\n",
            "NAME:  Wilbur Smith\n",
            "JOB: Network Engineer\n",
            "\n",
            "HTTPS://MYAPI.COM/WILBUR SMITH/PROFILE/NETWORK ENGINEER\n",
            "\n",
            "- John SMITH, Web Developer \n",
            "- Monica JOHNSON, Graphic Designer\n",
            "- Charlotte BROWN, Software Engineer \n",
            "- David WILLIAMS, Creative Director\n",
            "\n",
            "->\n",
            "Stephen Granger/Systems Engineer\n",
            "\n",
            "->\n",
            "Chadlyn Middleton/Software Developer\n",
            "\n",
            "NAME: Joanne Couch\n",
            "JOB: Copywriter\n",
            "\n",
            "NAME: Sally Freeman\n",
            "JOB: Financial Analyst\n",
            "\n",
            "Frank Wilkins / Designer\n",
            "\n",
            "Melanie Jones / Lawyer\n",
            "\n",
            "Robert Cole / Programmer\n",
            "\n",
            "Stephanie Cole / Chef\n",
            "\n",
            "Jonathan Singh / Psychoanalyst\n",
            "\n",
            "Eva Brown / Accountant\n",
            "\n",
            "Luke Mitchell / Engineer\n",
            "\n",
            "NAME: Lenny Estelle \n",
            "JOB: Game Designer \n",
            "\n",
            "https://myapi.com/LennyEstelle/profile/GameDesigner\n",
            "\n",
            "Max LEWIS, Web Developer \n",
            "Karen BROWN, Accountant \n",
            "Anna WILSON, Graphic Designer \n",
            "Trevor JOHNSON, Database Administrator \n",
            "Mia CHANG, Marketing Consultant \n",
            "\n",
            "\n",
            "Jeremy Baker/Data Analyst\n",
            "Thomas Roberts/Software Engineer\n",
            "Elizabeth White/Project Manager\n",
            "John Johnson/Graphic Designer\n",
            "Tim Miller/UX Designer\n",
            "\n",
            "Reshma Rahman/Freelance Writer\n",
            "\n",
            "Berin Delos/Legal Consultant\n",
            "\n",
            "Joanna Barker/Graphic Designer\n",
            "\n",
            "Gracie Dickson/Accountant\n",
            "\n",
            "Kendra Hargrove/Public Relations Assistant\n",
            "\n",
            "MARY SMITH/profile/Business Consultant \n",
            "JOE JOHNSON/profile/Technician \n",
            "OWEN GORDON/profile/Social Media Marketer \n",
            "ALEXANDRA KENNEDY/profile\n",
            "\n",
            "\n",
            "Samuel STRONG/ Prime Minister \n",
            "Corey BOLD/ State Senator \n",
            "Rebecca LIGHT/ City Council Member \n",
            "Luke DETERMINED/ Lobbyist\n",
            "\n",
            "Example Output\n",
            "https://myapi.com/SARAH/profile/Accountant\n",
            "\n",
            "\n",
            "NEW NAME/JOB:\n",
            "https://myapi.com/CAMERON/profile/Lawyer\n",
            "\n",
            "John Smith, Astronomer - https://myapi.com/JohnSmith/profile/Astronomer of\n",
            "\n",
            "Sally Jones, Graphic Designer - https://myapi.com/SallyJones/profile/GraphicDesigner\n",
            "\n",
            "Jackie FRANKLIN/Engineer https://myapi.com/JackieFranklin/profile/Engineer\n",
            "\n",
            "Charlie SILVA/Graphic Designer https://myapi.com/CharlieSilva/profile/GraphicDesign\n",
            "\n",
            "NAME - Alice Smith\n",
            "JOB - Artificer \n",
            "\n",
            "Alice Smith, an Artificer from https://myapi.com/AliceSmith/profile/Artificer, is an expert in creating intricate magical items. She is\n",
            "\n",
            "John Smith - Engineer\n",
            "https://myapi.com/JohnSmith/profile/Engineer\n",
            "\n",
            "John Smith, Author\n",
            "\n",
            "Linda Brown, Musician\n",
            "\n",
            "Nate Johnson, Editor\n",
            "\n",
            "Steve Anderson, Chef\n",
            "\n",
            "Kathy Hall, Photographer\n",
            "\n",
            "Tina Jones, Painter\n",
            "\n",
            "John Smith - Senior Engineer\n",
            "Susan Miller - Product Manager \n",
            "Jake Harris - Software Developer\n",
            "Annie Jones - Quality Assurance Analyst\n",
            "Mark Wilson - Technical Architect\n",
            "\n",
            "John Smith/Farmer\n",
            "\n",
            "https://myapi.com/John_Smith/profile/Farmer\n",
            "\n",
            "John Barkley / Web Developer\n",
            "\n",
            "June McIntire / Software Engineer\n",
            "\n",
            "Matthew Owens / Data Scientist\n",
            "\n",
            "Christopher Moore / Content Writer\n",
            "\n",
            "Alice Smith / Network Administrator\n",
            "\n",
            "Brian Johnson / UI/UX Designer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Context Manager pattern**"
      ],
      "metadata": {
        "id": "6y5e0SagouzO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "The \"Context Manager\" pattern is used to provide context and instructions to GPT-3 within a specific scope.\n",
        "\n",
        "In this example, the prompt defines a context within scope X (analyzing pieces of code) and instructs GPT-3 to consider Y (security aspects) and ignore Z (performance and optimization)."
      ],
      "metadata": {
        "id": "t8XxvkeSoreU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "# Define the Context Manager prompt\n",
        "context_manager_prompt = \"\"\"\n",
        "Within scope X\n",
        "Please consider Y\n",
        "Please ignore Z\n",
        "(Optional) start over\n",
        "\"\"\"\n",
        "\n",
        "# Define the specific context and instructions\n",
        "scope = \"analyzing the following pieces of code\"\n",
        "consider = \"security aspects\"\n",
        "ignore = \"performance and optimization\"\n",
        "\n",
        "# Construct the context with the instructions\n",
        "context = f\"\"\"\n",
        "Within scope {scope}\n",
        "Please consider {consider}\n",
        "Please ignore {ignore}\n",
        "\"\"\"\n",
        "\n",
        "# Send the Context Manager prompt to GPT-3\n",
        "response = openai.Completion.create(\n",
        "    engine=\"text-davinci-003\",\n",
        "    prompt=context_manager_prompt + context,\n",
        "    api_key=api_key,\n",
        "    max_tokens=500  # Adjust the max_tokens as needed\n",
        ")\n",
        "\n",
        "# Get the response from the model\n",
        "response_text = response.choices[0].text\n",
        "\n",
        "# Print the response\n",
        "print(response_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "32-GapycnxZI",
        "outputId": "649c1111-c5c7-40af-c0ab-7d7bc050f2eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(Optional) start over\n",
            "\n",
            "Within scope analyzing the following pieces of code\n",
            "Please consider logic implications and security aspects\n",
            "Please ignore user interface design and optimization\n",
            "(Optional) start over\n",
            "\n",
            "Within scope analyzing the following pieces of code\n",
            "Please consider logic implications, security aspects, and code complexity \n",
            "Please ignore user interface design, optimization, and visual styling. \n",
            "(Optional) start over\n",
            "\n",
            "Within scope analyzing the following pieces of code\n",
            "Please consider logic implications, security aspects, and code quality\n",
            "Please ignore user interface design, optimization, and visual styling.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tyHNe2rCooHf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}